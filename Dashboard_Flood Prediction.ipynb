{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uRyAXatfnCU-"},"outputs":[],"source":["import pandas as pd\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import numpy as np\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10754,"status":"ok","timestamp":1724331949634,"user":{"displayName":"Subhajit Paul","userId":"16517997475415567961"},"user_tz":-330},"id":"cP_rS9H8nWlf","outputId":"f34c6177-98d3-484f-ebb3-ebc2d8502fe9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.37.1-py2.py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n","Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n","Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n","Collecting tenacity<9,>=8.1.0 (from streamlit)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n","Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n","Collecting watchdog<5,>=2.1.5 (from streamlit)\n","  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n","Downloading streamlit-1.37.1-py2.py3-none-any.whl (8.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.37.1 tenacity-8.5.0 watchdog-4.0.2\n"]}],"source":["# prompt: install streamlit\n","\n","!pip install streamlit\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33641,"status":"ok","timestamp":1724331991018,"user":{"displayName":"Subhajit Paul","userId":"16517997475415567961"},"user_tz":-330},"id":"sPHmgq-jqvOl","outputId":"67c17f64-55c5-4e30-bb9c-07970728c958"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# prompt: mount drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZDsbYAWrG5g"},"outputs":[],"source":["# prompt: read csv from drive\n","\n","file_path = '/content/drive/MyDrive/Flood Prediction/flood_updated_1.csv'\n","df = pd.read_csv(file_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":497,"status":"ok","timestamp":1724332032718,"user":{"displayName":"Subhajit Paul","userId":"16517997475415567961"},"user_tz":-330},"id":"-vQy79g7sl33","outputId":"5b0da2e7-7473-4a6a-8704-e7bc95f5386e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing Flood_Prediction.py\n"]}],"source":["%%writefile Flood_Prediction.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":772,"status":"ok","timestamp":1724332036644,"user":{"displayName":"Subhajit Paul","userId":"16517997475415567961"},"user_tz":-330},"id":"-whtO7cOs9yN","outputId":"941c05ea-0ec0-40bf-b36a-93346cdc6c9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["34.125.50.145\n"]}],"source":["! wget -q -O - ipv4.icanhazip.com"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aqzupKwytBpT","outputId":"a714bdca-29ca-4f3c-9a0b-cfd63625b2cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.50.145:8501\u001b[0m\n","\u001b[0m\n","your url is: https://poor-windows-yawn.loca.lt\n","2024-08-22 16:48:57.485 Uncaught app exception\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 85, in exec_func_with_error_handling\n","    result = func()\n","  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 576, in code_to_exec\n","    exec(code, module.__dict__)\n","  File \"/content/Flood_Prediction.py\", line 120, in <module>\n","    model.fit(X_train, y_train)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\", line 678, in fit\n","    X, y = self._validate_data(\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 622, in _validate_data\n","    X, y = check_X_y(X, y, **check_params)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n","    X = check_array(\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 915, in check_array\n","    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n","    array = numpy.asarray(array, order=order, dtype=dtype)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 2084, in __array__\n","    arr = np.asarray(values, dtype=dtype)\n","ValueError: could not convert string to float: 'Light to Moderate Rain'\n","2024-08-22 16:49:19.225 Uncaught app exception\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 85, in exec_func_with_error_handling\n","    result = func()\n","  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 576, in code_to_exec\n","    exec(code, module.__dict__)\n","  File \"/content/Flood_Prediction.py\", line 120, in <module>\n","    model.fit(X_train, y_train)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\", line 678, in fit\n","    X, y = self._validate_data(\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 622, in _validate_data\n","    X, y = check_X_y(X, y, **check_params)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1146, in check_X_y\n","    X = check_array(\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 915, in check_array\n","    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n","    array = numpy.asarray(array, order=order, dtype=dtype)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 2084, in __array__\n","    arr = np.asarray(values, dtype=dtype)\n","ValueError: could not convert string to float: 'Light to Moderate Rain'\n"]}],"source":["! streamlit run Flood_Prediction.py & npx localtunnel --port 8501"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KnlF4v6h2sla"},"outputs":[],"source":["# prompt: give me a code for streamlit which can load data from df\n","\n","import streamlit as st\n","import pandas as pd\n","# ... other imports\n","\n","# Load the data (assuming 'df' is already loaded)\n","st.title(\"Flood Prediction App\")\n","\n","st.write(\"Here's our first attempt at using data to create a table:\")\n","st.write(df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NXuQfIVq3bPN"},"outputs":[],"source":["# prompt: give me the visualization of unique types of monsoonintensity\n","\n","# Assuming 'MonsoonIntensity' is the column containing monsoon intensity\n","unique_intensities = df['MonsoonIntensity'].unique()\n","st.write(\"Unique Monsoon Intensities:\")\n","st.write(unique_intensities)\n","\n","# Visualization using Plotly\n","fig = px.bar(df, x='MonsoonIntensity', title='Distribution of Monsoon Intensities')\n","st.plotly_chart(fig)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_K2AQ0W4cTy"},"outputs":[],"source":["# prompt: give me the visualization regarding how flood probability is canged with monsoon intensity in decreasing order\n","\n","# Sort the DataFrame by 'MonsoonIntensity' in descending order\n","df_sorted = df.sort_values('MonsoonIntensity', ascending=False)\n","\n","# Create the visualization\n","fig = px.bar(df_sorted, x='MonsoonIntensity', y='FloodProbability',\n","             title='Flood Probability vs. Monsoon Intensity (Decreasing Order)')\n","st.plotly_chart(fig)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gx6_dSBV5cjE"},"outputs":[],"source":["# prompt: streamlit code for correlation matrix\n","\n","# Correlation Matrix\n","st.subheader(\"Correlation Matrix\")\n","corr_matrix = df.corr()\n","fig = go.Figure(data=go.Heatmap(z=corr_matrix.values,\n","                                 x=corr_matrix.columns,\n","                                 y=corr_matrix.columns,\n","                                 colorscale='Viridis'))\n","st.plotly_chart(fig)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42ZiGdT98jSD"},"outputs":[],"source":["# prompt: how TopographyDrainage is affecting flood probability\n","\n","# Group the data by 'TopographyDrainage' and calculate the average flood probability for each group\n","grouped_data = df.groupby('TopographyDrainage')['FloodProbability'].mean().reset_index()\n","\n","# Create a bar chart to visualize the relationship\n","fig = px.bar(grouped_data, x='TopographyDrainage', y='FloodProbability',\n","             title='Average Flood Probability by Topography Drainage')\n","st.plotly_chart(fig)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QZQZGvje9rA1"},"outputs":[],"source":["# prompt: numeric encode all the columns except flood probability\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPdM43sHMndh"},"outputs":[],"source":["# prompt: give me streamlit code to visualize correlation among all the columns\n","\n","# Correlation Matrix\n","st.subheader(\"Correlation Matrix\")\n","corr_matrix = df.corr()\n","fig = go.Figure(data=go.Heatmap(z=corr_matrix.values,\n","                                 x=corr_matrix.columns,\n","                                 y=corr_matrix.columns,\n","                                 colorscale='Viridis'))\n","st.plotly_chart(fig)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iu78YnH3NKQp"},"outputs":[],"source":["# prompt: decode back all the columns except flood probability\n","\n","# ... (preceding code)\n","\n","# Store label encoders for each column\n","label_encoders = {}\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n","  label_encoders[column] = le  # Store the encoder\n","\n","# ... (other code)\n","\n","# Decode the columns\n","for column, le in label_encoders.items():\n","  df[column] = le.inverse_transform(df[column])\n","\n","# ... (rest of the code)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z52xdHASOTH_"},"outputs":[],"source":["# prompt: create a dropdown menu for political factor column and show the average flood prediction for a single political factor selected\n","\n","import pandas as pd\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import numpy as np\n","import os\n","from google.colab import drive\n","import streamlit as st\n","from sklearn.preprocessing import LabelEncoder\n","\n","!pip install streamlit\n","\n","\n","drive.mount('/content/drive')\n","\n","\n","file_path = '/content/drive/MyDrive/Flood Prediction/flood_updated_1.csv'\n","df = pd.read_csv(file_path)\n","\n","%%writefile Flood_Prediction.py\n","! wget -q -O - ipv4.icanhazip.com\n","! streamlit run Flood_Prediction.py & npx localtunnel --port 8501\n","\n","# ... other imports\n","\n","# Load the data (assuming 'df' is already loaded)\n","st.title(\"Flood Prediction App\")\n","\n","st.write(\"Here's our first attempt at using data to create a table:\")\n","st.write(df)\n","\n","\n","# Assuming 'MonsoonIntensity' is the column containing monsoon intensity\n","unique_intensities = df['MonsoonIntensity'].unique()\n","st.write(\"Unique Monsoon Intensities:\")\n","st.write(unique_intensities)\n","\n","# Visualization using Plotly\n","fig = px.bar(df, x='MonsoonIntensity', title='Distribution of Monsoon Intensities')\n","st.plotly_chart(fig)\n","\n","\n","# Sort the DataFrame by 'MonsoonIntensity' in descending order\n","df_sorted = df.sort_values('MonsoonIntensity', ascending=False)\n","\n","# Create the visualization\n","fig = px.bar(df_sorted, x='MonsoonIntensity', y='FloodProbability',\n","             title='Flood Probability vs. Monsoon Intensity (Decreasing Order)')\n","st.plotly_chart(fig)\n","\n","\n","# Correlation Matrix\n","st.subheader(\"Correlation Matrix\")\n","corr_matrix = df.corr()\n","fig = go.Figure(data=go.Heatmap(z=corr_matrix.values,\n","                                 x=corr_matrix.columns,\n","                                 y=corr_matrix.columns,\n","                                 colorscale='Viridis'))\n","st.plotly_chart(fig)\n","\n","\n","# Group the data by 'TopographyDrainage' and calculate the average flood probability for each group\n","grouped_data = df.groupby('TopographyDrainage')['FloodProbability'].mean().reset_index()\n","\n","# Create a bar chart to visualize the relationship\n","fig = px.bar(grouped_data, x='TopographyDrainage', y='FloodProbability',\n","             title='Average Flood Probability by Topography Drainage')\n","st.plotly_chart(fig)\n","\n","\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n","\n","\n","# Correlation Matrix\n","st.subheader(\"Correlation Matrix\")\n","corr_matrix = df.corr()\n","fig = go.Figure(data=go.Heatmap(z=corr_matrix.values,\n","                                 x=corr_matrix.columns,\n","                                 y=corr_matrix.columns,\n","                                 colorscale='Viridis'))\n","st.plotly_chart(fig)\n","\n","\n","# ... (preceding code)\n","\n","# Store label encoders for each column\n","label_encoders = {}\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n","  label_encoders[column] = le  # Store the encoder\n","\n","# ... (other code)\n","\n","# Decode the columns\n","for column, le in label_encoders.items():\n","  df[column] = le.inverse_transform(df[column])\n","\n","# ... (rest of the code)\n","\n","# Dropdown for Political Factor\n","selected_factor = st.selectbox('Select Political Factor', df['PoliticalFactors'].unique())\n","\n","# Filter data and calculate average flood probability\n","filtered_df = df[df['PoliticalFactors'] == selected_factor]\n","average_probability = filtered_df['FloodProbability'].mean()\n","\n","st.write(f\"Average Flood Probability for {selected_factor}: {average_probability:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7s2LVCTPWLn"},"outputs":[],"source":["# prompt: # Dropdown for Political Factor\n","# selected_factor = st.selectbox('Select Political Factor', df['PoliticalFactors'].unique())\n","# # Filter data and calculate average flood probability\n","# filtered_df = df[df['PoliticalFactors'] == selected_factor]\n","# average_probability = filtered_df['FloodProbability'].mean()\n","# st.write(f\"Average Flood Probability for {selected_factor}: {average_probability:.2f}\")\n","\n","# Dropdown for Political Factor\n","selected_factor = st.selectbox('Select Political Factor', df['PoliticalFactors'].unique())\n","\n","# Filter data and calculate average flood probability\n","filtered_df = df[df['PoliticalFactors'] == selected_factor]\n","average_probability = filtered_df['FloodProbability'].mean()\n","\n","st.write(f\"Average Flood Probability for {selected_factor}: {average_probability:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GGEp7cJ9Ph9I"},"outputs":[],"source":["# prompt: in the last code show the output in graphical pie chart out of 100% for the selected political factor only\n","\n","import pandas as pd\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import numpy as np\n","import os\n","from google.colab import drive\n","import streamlit as st\n","from sklearn.preprocessing import LabelEncoder\n","\n","!pip install streamlit\n","\n","\n","drive.mount('/content/drive')\n","\n","\n","file_path = '/content/drive/MyDrive/Flood Prediction/flood_updated_1.csv'\n","df = pd.read_csv(file_path)\n","\n","%%writefile Flood_Prediction.py\n","! wget -q -O - ipv4.icanhazip.com\n","! streamlit run Flood_Prediction.py & npx localtunnel --port 8501\n","\n","# ... other imports\n","\n","# Load the data (assuming 'df' is already loaded)\n","st.title(\"Flood Prediction App\")\n","\n","st.write(\"Here's our first attempt at using data to create a table:\")\n","st.write(df)\n","\n","\n","# Assuming 'MonsoonIntensity' is the column containing monsoon intensity\n","unique_intensities = df['MonsoonIntensity'].unique()\n","st.write(\"Unique Monsoon Intensities:\")\n","st.write(unique_intensities)\n","\n","# Visualization using Plotly\n","fig = px.bar(df, x='MonsoonIntensity', title='Distribution of Monsoon Intensities')\n","st.plotly_chart(fig)\n","\n","\n","# Sort the DataFrame by 'MonsoonIntensity' in descending order\n","df_sorted = df.sort_values('MonsoonIntensity', ascending=False)\n","\n","# Create the visualization\n","fig = px.bar(df_sorted, x='MonsoonIntensity', y='FloodProbability',\n","             title='Flood Probability vs. Monsoon Intensity (Decreasing Order)')\n","st.plotly_chart(fig)\n","\n","\n","# Correlation Matrix\n","st.subheader(\"Correlation Matrix\")\n","corr_matrix = df.corr()\n","fig = go.Figure(data=go.Heatmap(z=corr_matrix.values,\n","                                 x=corr_matrix.columns,\n","                                 y=corr_matrix.columns,\n","                                 colorscale='Viridis'))\n","st.plotly_chart(fig)\n","\n","\n","# Group the data by 'TopographyDrainage' and calculate the average flood probability for each group\n","grouped_data = df.groupby('TopographyDrainage')['FloodProbability'].mean().reset_index()\n","\n","# Create a bar chart to visualize the relationship\n","fig = px.bar(grouped_data, x='TopographyDrainage', y='FloodProbability',\n","             title='Average Flood Probability by Topography Drainage')\n","st.plotly_chart(fig)\n","\n","\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n","\n","\n","# Correlation Matrix\n","st.subheader(\"Correlation Matrix\")\n","corr_matrix = df.corr()\n","fig = go.Figure(data=go.Heatmap(z=corr_matrix.values,\n","                                 x=corr_matrix.columns,\n","                                 y=corr_matrix.columns,\n","                                 colorscale='Viridis'))\n","st.plotly_chart(fig)\n","\n","\n","# ... (preceding code)\n","\n","# Store label encoders for each column\n","label_encoders = {}\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n","  label_encoders[column] = le  # Store the encoder\n","\n","# ... (other code)\n","\n","# Decode the columns\n","for column, le in label_encoders.items():\n","  df[column] = le.inverse_transform(df[column])\n","\n","# ... (rest of the code)\n","\n","# Dropdown for Political Factor\n","selected_factor = st.selectbox('Select Political Factor', df['PoliticalFactors'].unique())\n","\n","# Filter data and calculate average flood probability\n","filtered_df = df[df['PoliticalFactors'] == selected_factor]\n","average_probability = filtered_df['FloodProbability'].mean()\n","\n","st.write(f\"Average Flood Probability for {selected_factor}: {average_probability:.2f}\")\n","\n","# Pie chart for selected political factor\n","labels = ['Flood Probability', 'No Flood Probability']\n","values = [average_probability, 1 - average_probability]\n","fig = go.Figure(data=[go.Pie(labels=labels, values=values)])\n","fig.update_layout(title=f'Flood Probability Distribution for {selected_factor}')\n","st.plotly_chart(fig)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7ihSxLyQg48"},"outputs":[],"source":["# prompt: There are multiple identical st.selectbox widgets with the same generated key.\n","# When a widget is created, it's assigned an internal key based on its structure. Multiple widgets with an identical structure will result in the same internal key, which causes this error.\n","# To fix this error, please pass a unique key argument to st.selectbox.\n","# fix this wrror for above code\n","\n","import pandas as pd\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import numpy as np\n","import os\n","from google.colab import drive\n","import streamlit as st\n","from sklearn.preprocessing import LabelEncoder\n","\n","!pip install streamlit\n","\n","\n","drive.mount('/content/drive')\n","\n","\n","file_path = '/content/drive/MyDrive/Flood Prediction/flood_updated_1.csv'\n","df = pd.read_csv(file_path)\n","\n","%%writefile Flood_Prediction.py\n","! wget -q -O - ipv4.icanhazip.com\n","! streamlit run Flood_Prediction.py & npx localtunnel --port 8501\n","\n","# ... other imports\n","\n","# Load the data (assuming 'df' is already loaded)\n","st.title(\"Flood Prediction App\")\n","\n","st.write(\"Here's our first attempt at using data to create a table:\")\n","st.write(df)\n","\n","\n","# Assuming 'MonsoonIntensity' is the column containing monsoon intensity\n","unique_intensities = df['MonsoonIntensity'].unique()\n","st.write(\"Unique Monsoon Intensities:\")\n","st.write(unique_intensities)\n","\n","# Visualization using Plotly\n","fig = px.bar(df, x='MonsoonIntensity', title='Distribution of Monsoon Intensities')\n","st.plotly_chart(fig)\n","\n","\n","# Sort the DataFrame by 'MonsoonIntensity' in descending order\n","df_sorted = df.sort_values('MonsoonIntensity', ascending=False)\n","\n","# Create the visualization\n","fig = px.bar(df_sorted, x='MonsoonIntensity', y='FloodProbability',\n","             title='Flood Probability vs. Monsoon Intensity (Decreasing Order)')\n","st.plotly_chart(fig)\n","\n","\n","# Correlation Matrix\n","st.subheader(\"Correlation Matrix\")\n","corr_matrix = df.corr()\n","fig = go.Figure(data=go.Heatmap(z=corr_matrix.values,\n","                                 x=corr_matrix.columns,\n","                                 y=corr_matrix.columns,\n","                                 colorscale='Viridis'))\n","st.plotly_chart(fig)\n","\n","\n","# Group the data by 'TopographyDrainage' and calculate the average flood probability for each group\n","grouped_data = df.groupby('TopographyDrainage')['FloodProbability'].mean().reset_index()\n","\n","# Create a bar chart to visualize the relationship\n","fig = px.bar(grouped_data, x='TopographyDrainage', y='FloodProbability',\n","             title='Average Flood Probability by Topography Drainage')\n","st.plotly_chart(fig)\n","\n","\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n","\n","\n","# Correlation Matrix\n","st.subheader(\"Correlation Matrix\")\n","corr_matrix = df.corr()\n","fig = go.Figure(data=go.Heatmap(z=corr_matrix.values,\n","                                 x=corr_matrix.columns,\n","                                 y=corr_matrix.columns,\n","                                 colorscale='Viridis'))\n","st.plotly_chart(fig)\n","\n","\n","# ... (preceding code)\n","\n","# Store label encoders for each column\n","label_encoders = {}\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n","  label_encoders[column] = le  # Store the encoder\n","\n","# ... (other code)\n","\n","# Decode the columns\n","for column, le in label_encoders.items():\n","  df[column] = le.inverse_transform(df[column])\n","\n","# ... (rest of the code)\n","\n","# Dropdown for Political Factor (with unique key)\n","selected_factor1 = st.selectbox('Select Political Factor', df['PoliticalFactors'].unique(), key='political_factor1')\n","\n","# Filter data and calculate average flood probability\n","filtered_df1 = df[df['PoliticalFactors'] == selected_factor1]\n","average_probability1 = filtered_df1['FloodProbability'].mean()\n","\n","st.write(f\"Average Flood Probability for {selected_factor1}: {average_probability1:.2f}\")\n","\n","# Pie chart for selected political factor (with unique key)\n","labels = ['Flood Probability', 'No Flood Probability']\n","values = [average_probability1, 1 - average_probability1]\n","fig = go.Figure(data=[go.Pie(labels=labels, values=values)])\n","fig.update_layout(title=f'Flood Probability Distribution for {selected_factor1}')\n","st.plotly_chart(fig, key='pie_chart1')\n","\n","\n","# Second dropdown for Political Factor (with unique key)\n","selected_factor2 = st.selectbox('Select Political Factor (Again)', df['PoliticalFactors'].unique(), key='political_factor2')\n","\n","# Filter data and calculate average flood probability\n","filtered_df2 = df[df['PoliticalFactors'] == selected_factor2]\n","average_probability2 = filtered_df2['FloodProbability'].mean()\n","\n","st.write(f\"Average Flood Probability for {selected_factor2}: {average_probability2:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dMpyvVGnTc0R"},"outputs":[],"source":["# prompt: how urbanization is related to flood probablity - show in scatterplot by encode decode the urbanization column. give the full code\n","\n","import pandas as pd\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import numpy as np\n","import os\n","from google.colab import drive\n","import streamlit as st\n","from sklearn.preprocessing import LabelEncoder\n","\n","!pip install streamlit\n","\n","\n","drive.mount('/content/drive')\n","\n","\n","file_path = '/content/drive/MyDrive/Flood Prediction/flood_updated_1.csv'\n","df = pd.read_csv(file_path)\n","\n","# Encode the 'Urbanization' column\n","le_urbanization = LabelEncoder()\n","df['Urbanization_encoded'] = le_urbanization.fit_transform(df['Urbanization'])\n","\n","# Create the scatter plot\n","fig = px.scatter(df, x='Urbanization_encoded', y='FloodProbability',\n","                 title='Flood Probability vs. Urbanization (Encoded)',\n","                 labels={'Urbanization_encoded': 'Urbanization'})\n","st.plotly_chart(fig)\n","\n","# Decode the 'Urbanization' column to display original values in the chart\n","df['Urbanization'] = le_urbanization.inverse_transform(df['Urbanization_encoded'])\n","\n","# Create the scatter plot with original Urbanization values\n","fig = px.scatter(df, x='Urbanization', y='FloodProbability',\n","                 title='Flood Probability vs. Urbanization',\n","                 trendline=\"ols\")  # Add a trendline\n","st.plotly_chart(fig)\n","\n","%%writefile Flood_Prediction.py\n","! wget -q -O - ipv4.icanhazip.com\n","! streamlit run Flood_Prediction.py & npx localtunnel --port 8501\n","\n","# ... (rest of your Streamlit code)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TECGs0RJY1-a"},"outputs":[],"source":["# prompt: encode urbanization and show scatterplot relation between urbanization and flood probability. but in graph x column should contain original name not the encoded value as lebel\n","\n","# ... (preceding code)\n","\n","# Encode the 'Urbanization' column\n","le_urbanization = LabelEncoder()\n","df['Urbanization_encoded'] = le_urbanization.fit_transform(df['Urbanization'])\n","\n","# Create the scatter plot\n","fig = px.scatter(df, x='Urbanization_encoded', y='FloodProbability',\n","                 title='Flood Probability vs. Urbanization (Encoded)',\n","                 labels={'Urbanization_encoded': 'Urbanization'})\n","st.plotly_chart(fig)\n","\n","# ... (rest of the code)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fvlSfURgd7cD"},"outputs":[],"source":["# prompt: le_urbanization = LabelEncoder()\n","# df['Urbanization_en'] = le_urbanization.fit_transform(df['Urbanization'])\n","# in this code i want show the mapping of encoding in urbanization in dropdown menu\n","\n","# ... (preceding code)\n","\n","le_urbanization = LabelEncoder()\n","df['Urbanization_en'] = le_urbanization.fit_transform(df['Urbanization'])\n","\n","# Create mapping of encoded values to original values\n","mapping = dict(zip(le_urbanization.classes_, le_urbanization.transform(le_urbanization.classes_)))\n","\n","# Display the mapping in a dropdown\n","selected_encoding = st.selectbox('Select Urbanization Encoding:', options=list(mapping.keys()))\n","st.write(f\"Encoded Value: {mapping[selected_encoding]}\")\n","\n","# ... (rest of the code)\n"]},{"cell_type":"code","source":["# prompt: Urbanization, InadequatePlanning, MonsoonIntensity, TopographyDrainage, RiverManagement, DrainageSystems, Deforestation, ClimateChange, CoastalVulnerability, and Landslides for these columns i want numerically encoded values in drop down. But encoding will be done for all columns except floodporobability. drop down box will be for given columns only\n","\n","# Store label encoders for each column\n","label_encoders = {}\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n","  label_encoders[column] = le  # Store the encoder\n","\n","# Columns for which you want dropdowns\n","dropdown_columns = ['Urbanization', 'InadequatePlanning', 'MonsoonIntensity',\n","                    'TopographyDrainage', 'RiverManagement', 'DrainageSystems',\n","                    'Deforestation', 'ClimateChange', 'CoastalVulnerability', 'Landslides']\n","\n","# Create dropdowns for selected columns\n","for column in dropdown_columns:\n","  # Create mapping of encoded values to original values\n","  mapping = dict(zip(label_encoders[column].classes_,\n","                     label_encoders[column].transform(label_encoders[column].classes_)))\n","\n","  # Display the mapping in a dropdown\n","  selected_encoding = st.selectbox(f'Select {column} Encoding:', options=list(mapping.keys()))\n","  st.write(f\"Encoded Value: {mapping[selected_encoding]}\")\n","\n","# ... (rest of the code)\n"],"metadata":{"id":"iMf0fysruap-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: numerical encoding for rest of the columns\n","\n","# ... (preceding code)\n","\n","# Columns to numerically encode (assuming these are the remaining columns)\n","columns_to_encode_numerically = ['AnnualRainFall', 'PopulationDensity', 'Elevation', 'GreenCover']\n","\n","# Apply numerical encoding (e.g., MinMaxScaler)\n","scaler = MinMaxScaler()\n","df[columns_to_encode_numerically] = scaler.fit_transform(df[columns_to_encode_numerically])\n","\n","# ... (rest of the code)\n"],"metadata":{"id":"HlAAmjX_wBQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: encode all the columns and give me a dropdown to show the encoded value except flood probability\n","\n","# Store label encoders for each column\n","label_encoders = {}\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column] = le.fit_transform(df[column])\n","  label_encoders[column] = le  # Store the encoder\n","\n","# Create dropdowns for all encoded columns (except 'FloodProbability')\n","for column in columns_to_encode:\n","  # Create mapping of encoded values to original values\n","  mapping = dict(zip(label_encoders[column].classes_,\n","                     label_encoders[column].transform(label_encoders[column].classes_)))\n","\n","  # Display the mapping in a dropdown\n","  selected_encoding = st.selectbox(f'Select {column} Encoding:', options=list(mapping.keys()))\n","  st.write(f\"Encoded Value: {mapping[selected_encoding]}\")\n"],"metadata":{"id":"e09kcVoTzuRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: encode all the columns and create new columns for the respective encoded value\n","\n","# Store label encoders for each column\n","label_encoders = {}\n","\n","# Select columns to encode (excluding 'FloodProbability')\n","columns_to_encode = df.columns[df.columns != 'FloodProbability']\n","\n","# Apply label encoding to each selected column and create new encoded columns\n","for column in columns_to_encode:\n","  le = LabelEncoder()\n","  df[column + '_encoded'] = le.fit_transform(df[column])\n","  label_encoders[column] = le  # Store the encoder\n"],"metadata":{"id":"-01ijYZ57ksU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: give me slider for all the columns from lowest encoded value to highest encoded value. slider name should be column name + \"predict\"\n","\n","# ... (preceding code)\n","\n","# Create sliders for all encoded columns (except 'FloodProbability')\n","for column in columns_to_encode:\n","  min_val = df[column + '_encoded'].min()\n","  max_val = df[column + '_encoded'].max()\n","  selected_value = st.slider(f\"{column} predict\", min_value=int(min_val), max_value=int(max_val), value=int(min_val))\n","  st.write(f\"Selected {column} Encoded Value: {selected_value}\")\n","\n","# ... (rest of the code)\n"],"metadata":{"id":"jlqCFq_e-DQ8"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFuJecwxbBf9J/RCy8jG9v"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}